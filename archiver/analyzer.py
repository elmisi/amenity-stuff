from __future__ import annotations

import json
import re
import time
from dataclasses import dataclass, replace
from pathlib import Path
from typing import Optional

from .ollama_client import generate

from .extractors.image import caption_image, extract_image_text_ocr
from .extractors.registry import extract_with_meta
from .pdf_extract import extract_pdf_text_with_meta
from .scanner import ScanItem
from .taxonomy import DEFAULT_TAXONOMY_LINES, Taxonomy, parse_taxonomy_lines, taxonomy_to_prompt_block
from .utils_filename import (
    cleanup_generic_words_in_name,
    ensure_extension,
    fallback_name_from_summary,
    name_separator,
    normalize_separators,
    propose_name_from_summary_and_facts,
    sanitize_name,
)
from .utils_json import extract_json_dict
from .utils_parsing import (
    coerce_date_candidates,
    coerce_list,
    extract_amount_token,
    extract_date_token,
    is_year,
    name_token_count,
    short_entity,
    split_and_repair_tokens,
)
from .prompts import (
    build_classify_prompt,
    build_facts_extraction_prompt,
    build_json_repair_prompt,
)

_DEFAULT_TAXONOMY, _ = parse_taxonomy_lines(DEFAULT_TAXONOMY_LINES)


@dataclass(frozen=True)
class AnalysisConfig:
    text_model: str = "qwen2.5:7b-instruct"
    vision_model: str = "moondream:latest"
    text_models: tuple[str, ...] = ()
    vision_models: tuple[str, ...] = ()
    ollama_base_url: str = "http://localhost:11434"
    output_language: str = "auto"  # auto | it | en
    taxonomy: Taxonomy = _DEFAULT_TAXONOMY
    filename_separator: str = "space"  # space | underscore | dash
    ocr_mode: str = "balanced"  # fast | balanced | high


@dataclass(frozen=True)
class AnalysisResult:
    status: str
    reason: Optional[str] = None
    category: Optional[str] = None
    reference_year: Optional[str] = None
    proposed_name: Optional[str] = None
    summary: Optional[str] = None
    confidence: Optional[float] = None
    model_used: Optional[str] = None
    summary_long: Optional[str] = None
    facts_json: Optional[str] = None
    llm_raw_output: Optional[str] = None
    extract_method: Optional[str] = None
    extract_time_s: Optional[float] = None
    llm_time_s: Optional[float] = None
    ocr_time_s: Optional[float] = None
    ocr_mode: Optional[str] = None


@dataclass(frozen=True)
class FactsResult:
    status: str  # scanned | skipped | error
    reason: Optional[str] = None
    summary_long: Optional[str] = None
    facts_json: Optional[str] = None
    confidence: Optional[float] = None
    llm_raw_output: Optional[str] = None
    extract_method: Optional[str] = None
    extract_time_s: Optional[float] = None
    llm_time_s: Optional[float] = None
    ocr_time_s: Optional[float] = None
    ocr_mode: Optional[str] = None
    model_used: Optional[str] = None


# _is_year moved to utils_parsing.is_year


def _extract_year_hint_from_path(path: Path) -> Optional[str]:
    """Best-effort year extraction from filename/path.

    Examples it should catch:
    - 2021/...
    - ..._12.2019_...
    - 17.03.2020
    - 20200105_101112
    """

    text = " ".join([*path.parts, path.name])

    # Prefer a directory or token that is exactly a year.
    for part in reversed(path.parts):
        if is_year(part):
            return part

    # Month-year like mm.yyyy or mm-yyyy or mm_yyyy.
    m = re.search(r"(?<!\d)\d{1,2}[._-](19\d{2}|20\d{2})(?!\d)", text)
    if m:
        return m.group(1)

    # Dates like dd.mm.yyyy or dd-mm-yyyy or dd_mm_yyyy.
    m = re.search(r"(?<!\d)\d{1,2}[._-]\d{1,2}[._-](19\d{2}|20\d{2})(?!\d)", text)
    if m:
        return m.group(1)

    # Dates like dd-mm-yy / dd.mm.yy (2-digit year). Use a conservative pivot.
    m = re.search(r"(?<!\d)\d{1,2}[._-]\d{1,2}[._-](\d{2})(?!\d)", text)
    if m:
        yy = int(m.group(1))
        # 00-69 -> 2000-2069, 70-99 -> 1970-1999
        return str(2000 + yy) if yy <= 69 else str(1900 + yy)

    # ISO date yyyy-mm-dd.
    m = re.search(r"(?<!\d)(19\d{2}|20\d{2})-\d{1,2}-\d{1,2}(?!\d)", text)
    if m:
        return m.group(1)

    # Timestamps like yyyymmdd or yyyymmdd_hhmmss.
    m = re.search(r"(?<!\d)(19\d{2}|20\d{2})(0[1-9]|1[0-2])([0-2]\d|3[01])(?!\d)", text)
    if m:
        return m.group(1)

    # Last resort: any year occurrence.
    m = re.search(r"(?<!\d)(19\d{2}|20\d{2})(?!\d)", text)
    if m:
        return m.group(1)

    return None


def _extract_year_hint_from_text(text: str) -> Optional[str]:
    # Keep it cheap and stable: first part of the document only.
    sample = text[:8000]
    years = re.findall(r"(?<!\d)(19\d{2}|20\d{2})(?!\d)", sample)
    if not years:
        return None
    counts: dict[str, int] = {}
    for y in years:
        counts[y] = counts.get(y, 0) + 1
    # Prefer most frequent; tie-breaker: latest year.
    best = sorted(counts.items(), key=lambda kv: (kv[1], kv[0]))[-1][0]
    return best


def _category_hint_from_signals(*, path: Path, text: Optional[str]) -> Optional[str]:
    hay = f"{path.as_posix()} {path.name}".lower()
    sample = (text or "")[:8000].lower()
    hay = hay + " " + sample

    # Home / utilities bills -> house.
    house_signals = [
        "bolletta",
        "fattura",
        "riepilogo fatture",
        "periodo riferimento",
        "protocollo",
        "gas naturale",
        "energia",
        "energia elettrica",
        "fornitura",
        "consumo",
        "kwh",
        "mc",
        "codice fiscale",
        "p.iva",
        "dolomiti energia",
        "enel",
        "iren",
        "acea",
        "acqua",
        "luce",
        "utenza",
    ]
    if any(s in hay for s in house_signals):
        return "house"

    # Technical docs / manuals -> tech.
    technical_signals = ["manual", "datasheet", "specification", "technical", "guide", "sdk", "api"]
    if any(s in hay for s in technical_signals):
        return "tech"

    return None


def _extract_json(text: str) -> Optional[dict]:
    return extract_json_dict(text)


_MAX_LLM_RAW_OUTPUT_CHARS = 12000


def _truncate_raw_output(text: str) -> str:
    raw = (text or "").strip()
    if len(raw) <= _MAX_LLM_RAW_OUTPUT_CHARS:
        return raw
    return raw[: _MAX_LLM_RAW_OUTPUT_CHARS - 200] + "\n...[truncated]...\n" + raw[-200:]


def _repair_json_dict_via_llm(*, model: str, raw_output: str, base_url: str) -> Optional[str]:
    snippet = _truncate_raw_output(raw_output)
    prompt = build_json_repair_prompt(snippet=snippet)
    try:
        gen = generate(model=model, prompt=prompt, base_url=base_url, timeout_s=60.0)
    except Exception:
        return None
    if gen.error:
        return None
    return gen.response


# The following functions have been moved to shared utilities:
# - _sanitize_name -> utils_filename.sanitize_name
# - _name_separator -> utils_filename.name_separator
# - _JOIN_BLOCKLIST -> utils_parsing.JOIN_BLOCKLIST
# - _split_and_repair_tokens -> utils_parsing.split_and_repair_tokens
# - _normalize_separators -> utils_filename.normalize_separators
# - _name_token_count -> utils_parsing.name_token_count
# - _coerce_list -> utils_parsing.coerce_list
# - _coerce_date_candidates -> utils_parsing.coerce_date_candidates


def _content_excerpt_for_llm(text: str, *, max_chars: int = 14000) -> str:
    """Keep within a predictable size while preserving high-signal regions.

    Strategy: if too long, keep head + tail (documents often contain totals/ids on the last part).
    """
    t = (text or "").strip()
    budget = max_chars
    # Very large documents can explode LLM latency; cap harder.
    if len(t) > max_chars * 8:
        budget = min(budget, 6000)
    elif len(t) > max_chars * 4:
        budget = min(budget, 9000)

    if len(t) <= budget:
        return t
    head = int(budget * 0.7)
    tail = budget - head
    return (t[:head].rstrip() + "\n\nâ€¦\n\n" + t[-tail:].lstrip()).strip()


# Additional functions moved to shared utilities:
# - _ensure_extension -> utils_filename.ensure_extension
# - _STOPWORDS -> utils_parsing.STOPWORDS
# - _GENERIC_NAME_TOKENS -> utils_parsing.GENERIC_NAME_TOKENS
# - _cleanup_generic_words_in_name -> utils_filename.cleanup_generic_words_in_name
# - _fallback_name_from_summary -> utils_filename.fallback_name_from_summary
# - _LEGAL_SUFFIXES_RE -> utils_parsing.LEGAL_SUFFIXES_RE
# - _short_entity -> utils_parsing.short_entity
# - _MONTHS -> utils_parsing.MONTHS
# - _extract_date_token -> utils_parsing.extract_date_token
# - _extract_amount_token -> utils_parsing.extract_amount_token
# - _propose_name_from_summary_and_facts -> utils_filename.propose_name_from_summary_and_facts


def _classify_from_text(
    *,
    model: str,
    content: str,
    filename: str,
    mtime_iso: str,
    base_url: str,
    reference_year_hint: Optional[str],
    category_hint: Optional[str],
    output_language: str,
    taxonomy: Taxonomy,
    filename_separator: str,
) -> AnalysisResult:
    categories = taxonomy.allowed_names
    taxonomy_block = taxonomy_to_prompt_block(taxonomy)
    prompt = build_classify_prompt(
        categories=list(categories),
        taxonomy_block=taxonomy_block,
        filename=filename,
        mtime_iso=mtime_iso,
        reference_year_hint=reference_year_hint,
        category_hint=category_hint,
        content=content,
        output_language=output_language,
    )
    try:
        gen = generate(model=model, prompt=prompt, base_url=base_url, timeout_s=180.0)
    except Exception as exc:  # noqa: BLE001 (MVP: best-effort)
        return AnalysisResult(status="error", reason=f"Ollama errore: {type(exc).__name__}", model_used=model)
    if gen.error:
        return AnalysisResult(status="error", reason=f"Ollama errore: {gen.error}", model_used=model)
    out = gen.response
    data = _extract_json(out)
    llm_raw_output: Optional[str] = None
    if not isinstance(data, dict):
        llm_raw_output = _truncate_raw_output(out)
        repaired = _repair_json_dict_via_llm(model=model, raw_output=out, base_url=base_url)
        if repaired:
            data = _extract_json(repaired)
    if not isinstance(data, dict):
        return AnalysisResult(
            status="skipped",
            reason="Unparseable output (JSON)",
            model_used=model,
            llm_raw_output=llm_raw_output,
        )

    skip_reason = data.get("skip_reason")
    if isinstance(skip_reason, str) and skip_reason.strip():
        return AnalysisResult(status="skipped", reason=skip_reason.strip(), model_used=model)

    category = data.get("category")
    if not isinstance(category, str) or category not in categories:
        category = "unknown"

    reference_year = data.get("reference_year")
    if reference_year is not None and not isinstance(reference_year, str):
        reference_year = None
    if isinstance(reference_year, str) and not is_year(reference_year.strip()):
        reference_year = None

    proposed_name = data.get("proposed_name")
    if not isinstance(proposed_name, str) or not proposed_name.strip():
        return AnalysisResult(status="skipped", reason="Missing proposed name", model_used=model)

    proposed_name = ensure_extension(sanitize_name(proposed_name), filename)
    proposed_name = cleanup_generic_words_in_name(proposed_name=proposed_name, original_filename=filename)
    proposed_name = normalize_separators(proposed_name, sep=filename_separator)

    summary = data.get("summary")
    if not isinstance(summary, str):
        summary = None
    summary_long = data.get("summary_long")
    if not isinstance(summary_long, str) or not summary_long.strip():
        llm_raw_output = llm_raw_output or _truncate_raw_output(out)
        return FactsResult(
            status="skipped",
            reason="Missing summary_long",
            model_used=model,
            llm_raw_output=llm_raw_output,
        )

    facts = {
        "language": data.get("language") if isinstance(data.get("language"), str) else None,
        "doc_type": data.get("doc_type") if isinstance(data.get("doc_type"), str) else None,
        "tags": coerce_list(data.get("tags")),
        "people": coerce_list(data.get("people")),
        "organizations": coerce_list(data.get("organizations")),
        "date_candidates": coerce_date_candidates(data.get("date_candidates")),
    }
    facts_json = json.dumps(facts, ensure_ascii=False, sort_keys=True)

    confidence = data.get("confidence")
    if isinstance(confidence, (int, float)):
        conf = float(confidence)
    else:
        conf = None

    if conf is not None and conf < 0.35:
        return AnalysisResult(
            status="skipped",
            reason="Low confidence",
            confidence=conf,
            model_used=model,
            llm_raw_output=llm_raw_output,
        )

    # If the model produced a generic/low-signal name, rebuild it from summary+facts.
    if summary_long:
        orgs = facts.get("organizations") if isinstance(facts.get("organizations"), list) else []
        org_hint = short_entity(str(orgs[0])) if orgs else ""
        low_signal = len(Path(proposed_name).stem) < 18 or name_token_count(proposed_name) < 4
        missing_entity = bool(org_hint) and (org_hint.lower().split()[0] not in proposed_name.lower())
        if low_signal or missing_entity:
            better = propose_name_from_summary_and_facts(
                summary_long=summary_long,
                facts=facts,
                reference_year=reference_year,
                original_filename=filename,
                filename_separator=filename_separator,
            )
            if better:
                proposed_name = better

    # If the proposed name is too short / low-signal, derive one from summary.
    if len(Path(proposed_name).stem) < 12 or name_token_count(proposed_name) < 3:
        proposed_name = fallback_name_from_summary(summary=summary, original_filename=filename, sep=filename_separator)
        proposed_name = cleanup_generic_words_in_name(proposed_name=proposed_name, original_filename=filename)
        proposed_name = normalize_separators(proposed_name, sep=filename_separator)

    # If category is unknown, fall back to hint.
    if category == "unknown" and category_hint in categories:
        category = category_hint

    # If the model didn't provide a usable year, fall back to filename/path hint.
    hint = reference_year_hint if (reference_year_hint and is_year(reference_year_hint)) else None
    if (not reference_year) and hint:
        reference_year = hint

    # If still missing, allow using a year embedded in the proposed name.
    if not reference_year:
        year_from_name = _extract_year_hint_from_path(Path(proposed_name))
        if year_from_name and is_year(year_from_name):
            reference_year = year_from_name

    # If both exist but differ, trust content only when confidence is sufficiently high.
    if reference_year and hint and reference_year != hint:
        if conf is None or conf < 0.6:
            reference_year = hint

    return AnalysisResult(
        status="ready",
        category=category,
        reference_year=reference_year,
        proposed_name=proposed_name,
        summary=(summary or "").strip()[:200] or None,
        confidence=conf,
        model_used=model,
        summary_long=(summary_long or "").strip()[:4000] or None,
        facts_json=facts_json,
        llm_raw_output=llm_raw_output,
    )

def _text_model_candidates(cfg: AnalysisConfig) -> tuple[str, ...]:
    if cfg.text_models:
        return cfg.text_models
    return (cfg.text_model,)


def _vision_model_candidates(cfg: AnalysisConfig) -> tuple[str, ...]:
    if cfg.vision_models:
        return cfg.vision_models
    return (cfg.vision_model,)


def _try_text_models(
    *,
    cfg: AnalysisConfig,
    content: str,
    filename: str,
    mtime_iso: str,
    reference_year_hint: Optional[str],
    category_hint: Optional[str],
) -> AnalysisResult:
    last: AnalysisResult | None = None
    for model in _text_model_candidates(cfg):
        res = _classify_from_text(
            model=model,
            content=content,
            filename=filename,
            mtime_iso=mtime_iso,
            base_url=cfg.ollama_base_url,
            reference_year_hint=reference_year_hint,
            category_hint=category_hint,
            output_language=cfg.output_language,
            taxonomy=cfg.taxonomy,
            filename_separator=cfg.filename_separator,
        )
        last = res
        if res.status == "ready":
            return res
    return last or AnalysisResult(status="error", reason="No text models available")


def _extract_facts_from_text(
    *,
    model: str,
    content: str,
    filename: str,
    mtime_iso: str,
    base_url: str,
    year_hint_filename: Optional[str],
    year_hint_text: Optional[str],
    output_language: str,
) -> FactsResult:
    prompt = build_facts_extraction_prompt(
        filename=filename,
        mtime_iso=mtime_iso,
        year_hint_filename=year_hint_filename,
        year_hint_text=year_hint_text,
        content=content,
        output_language=output_language,
    )
    try:
        gen = generate(model=model, prompt=prompt, base_url=base_url, timeout_s=180.0)
    except Exception as exc:  # noqa: BLE001
        return FactsResult(status="error", reason=f"Ollama errore: {type(exc).__name__}", model_used=model)
    if gen.error:
        return FactsResult(status="error", reason=f"Ollama errore: {gen.error}", model_used=model)

    out = gen.response
    data = _extract_json(out)
    llm_raw_output: Optional[str] = None
    if not isinstance(data, dict):
        llm_raw_output = _truncate_raw_output(out)
        repaired = _repair_json_dict_via_llm(model=model, raw_output=out, base_url=base_url)
        if repaired:
            data = _extract_json(repaired)
    if not isinstance(data, dict):
        return FactsResult(
            status="skipped",
            reason="Unparseable output (JSON)",
            model_used=model,
            llm_raw_output=llm_raw_output,
        )

    skip_reason = data.get("skip_reason")
    if isinstance(skip_reason, str) and skip_reason.strip():
        return FactsResult(status="skipped", reason=skip_reason.strip(), model_used=model)

    summary_long = data.get("summary_long")
    if not isinstance(summary_long, str) or not summary_long.strip():
        summary_long = None

    confidence = data.get("confidence")
    conf = float(confidence) if isinstance(confidence, (int, float)) else None
    if conf is not None and conf < 0.30:
        return FactsResult(
            status="skipped",
            reason="Low confidence",
            confidence=conf,
            model_used=model,
            llm_raw_output=llm_raw_output,
        )

    facts = {
        "language": data.get("language") if isinstance(data.get("language"), str) else None,
        "doc_type": data.get("doc_type") if isinstance(data.get("doc_type"), str) else None,
        "purpose": data.get("purpose") if isinstance(data.get("purpose"), str) else None,
        "tags": coerce_list(data.get("tags")),
        "people": coerce_list(data.get("people")),
        "organizations": coerce_list(data.get("organizations")),
        "addresses": coerce_list(data.get("addresses")),
        "amounts": data.get("amounts") if isinstance(data.get("amounts"), list) else [],
        "identifiers": data.get("identifiers") if isinstance(data.get("identifiers"), list) else [],
        "date_candidates": coerce_date_candidates(data.get("date_candidates")),
        "year_hint_filename": year_hint_filename,
        "year_hint_text": year_hint_text,
    }
    facts_json = json.dumps(facts, ensure_ascii=False, sort_keys=True)

    return FactsResult(
        status="scanned",
        summary_long=(summary_long or "").strip()[:4000] or None,
        facts_json=facts_json,
        confidence=conf,
        model_used=model,
        llm_raw_output=llm_raw_output,
    )


def extract_facts_item(item: ScanItem, *, config: AnalysisConfig) -> FactsResult:
    path = item.path
    if item.status not in {"pending", "skipped", "error"}:
        return FactsResult(status=item.status, reason=item.reason)

    year_hint_filename = _extract_year_hint_from_path(path)

    def skipped(reason: str) -> FactsResult:
        return FactsResult(status="skipped", reason=reason)

    if item.kind in {"pdf", "doc", "docx", "odt", "xls", "xlsx", "json", "md", "txt", "rtf", "svg", "kmz"}:
        text, reason, meta = extract_with_meta(kind=item.kind, path=path, ocr_mode=config.ocr_mode)
        if not text:
            if item.kind == "pdf":
                fallback = "No extractable PDF text"
            elif item.kind in {"doc", "docx", "odt", "xls", "xlsx"}:
                fallback = "No extractable office text"
            else:
                fallback = "No extractable text"

            res = skipped(reason or fallback)
            if meta:
                res = replace(
                    res,
                    extract_method=getattr(meta, "method", None),
                    extract_time_s=getattr(meta, "extract_time_s", None),
                    ocr_time_s=getattr(meta, "ocr_time_s", None),
                    ocr_mode=getattr(meta, "ocr_mode", None),
                )
            return res
        year_hint_text = _extract_year_hint_from_text(text)
        excerpt = _content_excerpt_for_llm(text, max_chars=14000)
        model = _text_model_candidates(config)[0] if _text_model_candidates(config) else config.text_model
        t0 = time.perf_counter()
        res = _extract_facts_from_text(
            model=model,
            content=excerpt,
            filename=path.name,
            mtime_iso=item.mtime_iso,
            base_url=config.ollama_base_url,
            year_hint_filename=year_hint_filename,
            year_hint_text=year_hint_text,
            output_language=config.output_language,
        )
        llm_elapsed = time.perf_counter() - t0
        if meta:
            res = replace(
                res,
                extract_method=getattr(meta, "method", None),
                extract_time_s=getattr(meta, "extract_time_s", None),
                ocr_time_s=getattr(meta, "ocr_time_s", None),
                ocr_mode=getattr(meta, "ocr_mode", None),
            )
        return replace(res, llm_time_s=llm_elapsed)

    if item.kind == "image":
        max_chars = 14000
        ocr_text, ocr_meta = extract_image_text_ocr(path, max_chars=max_chars, ocr_mode=config.ocr_mode)
        if ocr_text and ocr_meta:
            year_hint_text = _extract_year_hint_from_text(ocr_text)
            excerpt = _content_excerpt_for_llm(ocr_text, max_chars=max_chars)
            model = _text_model_candidates(config)[0] if _text_model_candidates(config) else config.text_model
            t1 = time.perf_counter()
            res = _extract_facts_from_text(
                model=model,
                content=excerpt,
                filename=path.name,
                mtime_iso=item.mtime_iso,
                base_url=config.ollama_base_url,
                year_hint_filename=year_hint_filename,
                year_hint_text=year_hint_text,
                output_language=config.output_language,
            )
            llm_elapsed = time.perf_counter() - t1
            return replace(
                res,
                extract_method="ocr",
                extract_time_s=ocr_meta.ocr_time_s,
                ocr_time_s=ocr_meta.ocr_time_s,
                ocr_mode=config.ocr_mode,
                llm_time_s=llm_elapsed,
                model_used=model,
            )

        # Fallback: use a vision model to caption the image.
        if config.output_language == "it":
            caption_prompt = "Describe this image in one sentence in Italian."
        else:
            caption_prompt = "Describe this image in one sentence in English."
        caption, cap_meta = caption_image(
            path,
            vision_models=tuple(_vision_model_candidates(config)),
            prompt=caption_prompt,
            base_url=config.ollama_base_url,
            timeout_s=180.0,
        )
        if not caption:
            msg = "Empty caption" if not cap_meta.last_error else f"Vision error: {cap_meta.last_error}"
            return skipped(msg)

        model = _text_model_candidates(config)[0] if _text_model_candidates(config) else config.text_model
        t1 = time.perf_counter()
        res = _extract_facts_from_text(
            model=model,
            content=f"IMAGE_CAPTION: {caption}",
            filename=path.name,
            mtime_iso=item.mtime_iso,
            base_url=config.ollama_base_url,
            year_hint_filename=year_hint_filename,
            year_hint_text=None,
            output_language=config.output_language,
        )
        llm_elapsed = time.perf_counter() - t1
        used = model
        if cap_meta.vision_model_used:
            used = f"{model} (vision: {cap_meta.vision_model_used})"
        return replace(
            res,
            llm_time_s=llm_elapsed,
            model_used=used,
            extract_method="vision",
            extract_time_s=cap_meta.caption_time_s,
            ocr_time_s=None,
            ocr_mode=None,
        )

    return skipped("Unsupported file type")


def analyze_item(item: ScanItem, *, config: AnalysisConfig) -> AnalysisResult:
    path = item.path
    if item.status != "pending":
        return AnalysisResult(status=item.status, reason=item.reason)

    filename_year_hint = _extract_year_hint_from_path(path)

    def skipped(reason: str) -> AnalysisResult:
        return AnalysisResult(
            status="skipped",
            reason=reason,
            category="unknown",
            reference_year=filename_year_hint,
            proposed_name=path.name,
        )

    def skipped_with_year(reason: str, year_hint: Optional[str]) -> AnalysisResult:
        return AnalysisResult(
            status="skipped",
            reason=reason,
            category="unknown",
            reference_year=year_hint,
            proposed_name=path.name,
        )

    if item.kind == "pdf":
        text, reason, meta = extract_pdf_text_with_meta(path, ocr_mode=config.ocr_mode)
        if not text:
            return skipped(reason or "No extractable PDF text")
        content_year_hint = _extract_year_hint_from_text(text)
        effective_year_hint = filename_year_hint or content_year_hint
        category_hint = _category_hint_from_signals(path=path, text=text)
        t0 = time.perf_counter()
        res = _try_text_models(
            cfg=config,
            content=text,
            filename=path.name,
            mtime_iso=item.mtime_iso,
            reference_year_hint=effective_year_hint,
            category_hint=category_hint,
        )
        llm_elapsed = time.perf_counter() - t0
        if meta:
            res = replace(
                res,
                extract_method=meta.method,
                extract_time_s=meta.extract_time_s,
                ocr_time_s=meta.ocr_time_s,
                ocr_mode=meta.ocr_mode,
            )
        res = replace(res, llm_time_s=llm_elapsed)
        if res.status == "skipped":
            return replace(
                res,
                category="unknown",
                reference_year=res.reference_year or effective_year_hint,
                proposed_name=path.name,
            )
        return res

    if item.kind == "image":
        effective_year_hint = filename_year_hint
        category_hint = _category_hint_from_signals(path=path, text=None)
        max_chars = 15000
        ocr_text, ocr_meta = extract_image_text_ocr(path, max_chars=max_chars, ocr_mode=config.ocr_mode)
        if ocr_text and ocr_meta:
            content_year_hint = _extract_year_hint_from_text(ocr_text)
            effective_year_hint = effective_year_hint or content_year_hint
            t0 = time.perf_counter()
            res = _try_text_models(
                cfg=config,
                content=_content_excerpt_for_llm(ocr_text, max_chars=14000),
                filename=path.name,
                mtime_iso=item.mtime_iso,
                reference_year_hint=effective_year_hint,
                category_hint=category_hint,
            )
            llm_elapsed = time.perf_counter() - t0
            res = replace(
                res,
                extract_method="ocr",
                extract_time_s=ocr_meta.ocr_time_s,
                ocr_time_s=ocr_meta.ocr_time_s,
                ocr_mode=config.ocr_mode,
                llm_time_s=llm_elapsed,
            )
        else:
            # Fallback: use a vision model to caption the image.
            if config.output_language == "it":
                caption_prompt = "Describe this image in one sentence in Italian."
            else:
                caption_prompt = "Describe this image in one sentence in English."
            caption, cap_meta = caption_image(
                path,
                vision_models=tuple(_vision_model_candidates(config)),
                prompt=caption_prompt,
                base_url=config.ollama_base_url,
                timeout_s=180.0,
            )
            cap_elapsed = cap_meta.caption_time_s
            if not caption:
                msg = "Empty caption" if not cap_meta.last_error else f"Vision error: {cap_meta.last_error}"
                return skipped_with_year(msg, effective_year_hint)
            t0 = time.perf_counter()
            res = _try_text_models(
                cfg=config,
                content=f"IMAGE_CAPTION: {caption}",
                filename=path.name,
                mtime_iso=item.mtime_iso,
                reference_year_hint=effective_year_hint,
                category_hint=category_hint,
            )
            llm_elapsed = time.perf_counter() - t0
            res = replace(res, llm_time_s=llm_elapsed, extract_method="vision", extract_time_s=cap_elapsed)
            if cap_meta.vision_model_used and res.model_used:
                res = replace(res, model_used=f"{res.model_used} (vision: {cap_meta.vision_model_used})")

        if res.status == "skipped":
            return replace(
                res,
                category="unknown",
                reference_year=res.reference_year or effective_year_hint,
                proposed_name=path.name,
            )
        return res

    return skipped_with_year("Unsupported file type", filename_year_hint)
